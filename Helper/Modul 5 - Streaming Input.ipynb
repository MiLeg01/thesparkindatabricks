{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbce0cf0-08af-41a2-b266-cddd59397edc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./_config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b228fb3f-2c89-4f7f-86fc-d06f130378e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DBFS Pfad\n",
    "DATA_PATH = f\"{CATALOG}.{SCHEMA}.yellow_tripdata_2025_01\" # \"/FileStore/tables/yellow_tripdata_2025_01-1.parquet\"\n",
    "LOOKUP_PATH = f\"{CATALOG}.{SCHEMA}.taxi_zone_lookup\"\n",
    "\n",
    "# DataFrame laden\n",
    "df_taxi = spark.read.table(DATA_PATH)\n",
    "df_lookup = spark.read.table(LOOKUP_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4c71e97-a558-413b-af44-89f29cda68c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Zielvolume\n",
    "streaming_input_volume = f\"Volumes/{CATALOG}/{SCHEMA}/taxi_volume\"\n",
    "streaming_input_folder = f\"{streaming_input_volume}/jsonfolder\"\n",
    "\n",
    "# Delta Pfad\n",
    "\n",
    "dbutils.fs.mkdirs(f\"/{streaming_input_volume}/jsonfolder\")\n",
    "\n",
    "df_taxi_small = df_taxi.limit(10000)\n",
    "\n",
    "for i, row in enumerate(df_taxi_small.collect()):\n",
    "    # Row in dict umwandeln, Datum als ISO\n",
    "    row_dict = {k: (v.isoformat() if hasattr(v, 'isoformat') else v) for k, v in row.asDict().items() }\n",
    "    \n",
    "    # Dateiname im DBFS-Pfad\n",
    "    file_path = f\"/{streaming_input_folder}/event_{i:06d}.json\"\n",
    "    \n",
    "    # JSON schreiben\n",
    "    dbutils.fs.put(file_path, json.dumps(row_dict), overwrite=True)\n",
    "    \n",
    "    print(f\"Wrote event {i+1}\")\n",
    "    time.sleep(3)  # Pause f√ºr Streaming-Simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "942eb6e1-754c-41ea-b604-5cfad7280c8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#In ein Delta Format rein streamen\n",
    "\n",
    "### YOUR CODE HERE ###\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Modul 5 - Streaming Input",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
